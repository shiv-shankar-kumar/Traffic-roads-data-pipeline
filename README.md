# ğŸš¦ Real-Time Traffic & Roads Data Pipeline

This project simulates a real-time data engineering pipeline using traffic and road datasets. Built on **Azure Databricks** and **Azure Data Lake Storage Gen2**, it leverages the **Medallion Architecture** to ingest, transform, and serve data through Bronze, Silver, and Gold layers. The solution also integrates **Spark Structured Streaming**, **Delta Lake**, **Unity Catalog**, and **CI/CD** best practices for production-grade data engineering.

---

## ğŸ§­ Project Objectives

- Simulate a real-time ETL pipeline using traffic and road data.
- Ingest and transform data using **Structured Streaming** with **Autoloader**.
- Apply Medallion Architecture: Bronze â†’ Silver â†’ Gold layers.
- Govern data access and manage metadata using **Unity Catalog**.
- Implement **CI/CD** pipelines for deployment and automation.
- Enable observability and fault-tolerance with **Delta Live Tables**.

---

## ğŸ§° Tech Stack

| Category               | Tools/Technologies                             |
|------------------------|------------------------------------------------|
| Cloud Platform         | Azure Data Lake Gen2, Azure DevOps             |
| Processing Engine      | Apache Spark (Structured Streaming)            |
| Notebook Environment   | Azure Databricks (with Unity Catalog)          |
| Storage Format         | Delta Lake                                     |
| Pipeline Orchestration | Delta Live Tables, Azure DevOps Pipelines      |
| Governance             | Unity Catalog                                  |

---

## ğŸ—ï¸ Architecture Overview
Landing Zone (ADLS Gen2)
â†“ (Autoloader + Structured Streaming)
Bronze Layer (Raw Ingestion)
â†“ (Transformations - Filtering, Parsing)
Silver Layer (Cleaned, Modeled Data)
â†“ (Minimal Aggregation)
Gold Layer (Reporting & Consumption)



---

## ğŸ§ª Features

- âœ… Incremental & real-time ingestion with **Spark Autoloader**
- âœ… **Delta Lake** for ACID compliance and time travel
- âœ… **Unity Catalog** for centralized governance
- âœ… **CI/CD** pipeline to deploy notebooks, workflows & access policies
- âœ… Real-time transformation using **Structured Streaming**
- âœ… **Delta Live Tables** for declarative data pipeline management

---

## ğŸ“ Project Structure (Example)
```
Real-Time-Traffic-Pipeline/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_landing_to_bronze_stream.py
â”‚ â”œâ”€â”€ 02_bronze_to_silver.py
â”‚ â”œâ”€â”€ 03_silver_to_gold.py
â”‚ â””â”€â”€ utils/
â”œâ”€â”€ pipelines/
â”‚ â””â”€â”€ delta_live_config.json
â”œâ”€â”€ ci_cd/
â”‚ â””â”€â”€ azure_pipeline.yml
â”œâ”€â”€ unity_catalog/
â”‚ â”œâ”€â”€ schema_definitions/
â”‚ â””â”€â”€ access_controls/
â”œâ”€â”€ data_samples/
â”‚ â”œâ”€â”€ traffic_data.csv
â”‚ â””â”€â”€ roads_data.csv
â””â”€â”€ README.md
```

---

## ğŸš€ How to Run the Project

1. **Upload datasets** to ADLS Gen2 container (`landing-zone`).
2. Run `01_landing_to_bronze_stream.py` in Databricks to ingest data using Autoloader.
3. Execute transformation notebooks in sequence.
4. Configure Unity Catalog with `schema_definitions` and ACLs.
5. Trigger Azure DevOps pipeline for CI/CD deployment.
6. Monitor pipeline execution via Delta Live Tables UI.

---

## ğŸ“Š Expected Output

- Real-time dashboards powered by clean, structured data.
- Auditable data governance with Unity Catalog.
- Automated deployment and version control of all data assets.

---

## ğŸ§  Key Concepts Demonstrated

- Medallion Architecture (Bronze, Silver, Gold)
- Structured Streaming and Incremental Loads
- Unity Catalog (Object Model & Access Control)
- Delta Live Tables and CI/CD for production pipelines

---

## ğŸ§  Key Concepts Demonstrated

- Medallion Architecture (Bronze, Silver, Gold)
- Structured Streaming and Incremental Loads
- Unity Catalog (Object Model & Access Control)
- Delta Live Tables and CI/CD for production pipelines

---

## ğŸ“Œ Notes

- This project simulates a real-time production scenario using historical data.
- No sensitive data is includedâ€”datasets are synthetic or anonymized.

---



